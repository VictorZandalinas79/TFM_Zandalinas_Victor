{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c52851e",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [15]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6052e3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:01.346707Z",
     "iopub.status.busy": "2025-03-25T19:05:01.346430Z",
     "iopub.status.idle": "2025-03-25T19:05:01.350242Z",
     "shell.execute_reply": "2025-03-25T19:05:01.349814Z"
    },
    "papermill": {
     "duration": 0.020281,
     "end_time": "2025-03-25T19:05:01.351861",
     "exception": false,
     "start_time": "2025-03-25T19:05:01.331580",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "alpha = 0.6\n",
    "ratio = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dbbfd21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:01.367433Z",
     "iopub.status.busy": "2025-03-25T19:05:01.367212Z",
     "iopub.status.idle": "2025-03-25T19:05:01.781727Z",
     "shell.execute_reply": "2025-03-25T19:05:01.781439Z"
    },
    "papermill": {
     "duration": 0.422285,
     "end_time": "2025-03-25T19:05:01.782640",
     "exception": false,
     "start_time": "2025-03-25T19:05:01.360355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import datetime as dt\n",
    "from termcolor import colored\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b376fc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:01.788948Z",
     "iopub.status.busy": "2025-03-25T19:05:01.788790Z",
     "iopub.status.idle": "2025-03-25T19:05:01.791165Z",
     "shell.execute_reply": "2025-03-25T19:05:01.790854Z"
    },
    "papermill": {
     "duration": 0.006398,
     "end_time": "2025-03-25T19:05:01.792016",
     "exception": false,
     "start_time": "2025-03-25T19:05:01.785618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta creada: /Users/imac/Programas/Datos_API_Bepro/Alaves_Github/BePro/documentacion/../data_backup/archivos_parquet/Liga Nacional Juvenil - Grupo 4\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = \"https://staging.data-api.bepro11.com/api\"\n",
    "API_TOKEN = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJoYXNoZWRfaWQiOiJiZXByb0FQSUtleV82VTAifQ.eJPGw3z0UF22uLxWWf2OAcGo3jkUYbYnCBF8XUQ842U\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\"\n",
    "}\n",
    "\n",
    "# Obtener la ruta absoluta del directorio actual (donde está el notebook)\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "\n",
    "# Subir un nivel para llegar a la raíz del proyecto (BePro)\n",
    "project_root = os.path.dirname(current_dir)\n",
    "\n",
    "# Construir la ruta completa desde la raíz del proyecto\n",
    "BASE_PATH = os.path.join(project_root, \"..\", \"data_backup\", \"archivos_parquet\", \"Liga Nacional Juvenil - Grupo 4\")\n",
    "\n",
    "# Crear el directorio si no existe\n",
    "os.makedirs(BASE_PATH, exist_ok=True)\n",
    "\n",
    "# Imprimir la ruta para verificar\n",
    "print(f\"Ruta creada: {BASE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea91bef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:01.799543Z",
     "iopub.status.busy": "2025-03-25T19:05:01.799343Z",
     "iopub.status.idle": "2025-03-25T19:05:02.163142Z",
     "shell.execute_reply": "2025-03-25T19:05:02.162804Z"
    },
    "papermill": {
     "duration": 0.368986,
     "end_time": "2025-03-25T19:05:02.164391",
     "exception": false,
     "start_time": "2025-03-25T19:05:01.795405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha guardado el archivo leagues.parquet\n",
      "Se han guardado 6 ligas en leagues.parquet\n",
      "DataFrame df_leagues creado y disponible globalmente.\n",
      "\n",
      "Contenido de df_leagues:\n",
      "     id                       name                           name_en  \\\n",
      "0  1184          Tercera RFEF - G4                              None   \n",
      "1   698      D. Honor Juvenil - G2  División Honor Juvenil - Grupo 2   \n",
      "2  1179          Segunda RFEF - G2                              None   \n",
      "3  1719  División de Honor - Araba         División de Honor - Araba   \n",
      "4  1992          Copa Vasca Cadete                 Copa Vasca Cadete   \n",
      "5  2154          Liga Vasca Cadete                 Liga Vasca Cadete   \n",
      "\n",
      "  iso_country_code age_limit  division                season_ids  \n",
      "0               ES     ADULT      13.0        [1605, 3362, 4104]  \n",
      "1               ES       U19      32.0  [1626, 2399, 3303, 4024]  \n",
      "2               ES     ADULT       6.0        [2382, 3259, 4019]  \n",
      "3               ES     ADULT      32.0                    [2565]  \n",
      "4               ES       U16       NaN                    [3001]  \n",
      "5               ES       U16      61.0        [3728, 3364, 4232]  \n"
     ]
    }
   ],
   "source": [
    "# Variable global para almacenar el DataFrame de ligas\n",
    "df_leagues = None\n",
    "\n",
    "def create_folder_structure():\n",
    "    \"\"\"\n",
    "    Crea la estructura de carpetas necesaria para almacenar los datos.\n",
    "    \"\"\"\n",
    "    os.makedirs(BASE_PATH, exist_ok=True)\n",
    "    return BASE_PATH\n",
    "\n",
    "def getResults(endpoint, params=None):\n",
    "    \"\"\"\n",
    "    Realiza una solicitud a la API de Bepro y devuelve los resultados.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}{endpoint}\"\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()  # Lanza una excepción si hay un error HTTP\n",
    "    return response.json()\n",
    "\n",
    "def save_to_parquet(df, filename, BASE_PATH):\n",
    "    \"\"\"\n",
    "    Guarda el DataFrame en un archivo Parquet.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(BASE_PATH, filename)\n",
    "    df.to_parquet(file_path, index=False)\n",
    "    print(f\"Se ha guardado el archivo {filename}\")\n",
    "\n",
    "def get_leagues():\n",
    "    \"\"\"\n",
    "    Obtiene la lista de ligas de la API, la convierte en un DataFrame y la guarda en un Parquet.\n",
    "    \"\"\"\n",
    "    global df_leagues\n",
    "    leagues = getResults('/leagues')\n",
    "    \n",
    "    if leagues['result']:\n",
    "        df_leagues = json_normalize(leagues['result'])\n",
    "        BASE_PATH = create_folder_structure()\n",
    "        save_to_parquet(df_leagues, \"leagues.parquet\", BASE_PATH)\n",
    "        print(f\"Se han guardado {len(df_leagues)} ligas en leagues.parquet\")\n",
    "        print(\"DataFrame df_leagues creado y disponible globalmente.\")\n",
    "    else:\n",
    "        print(\"No se encontraron datos de ligas\")\n",
    "        df_leagues = pd.DataFrame()  # DataFrame vacío si no hay resultados\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta todo el proceso de extracción y almacenamiento de datos.\n",
    "    \"\"\"\n",
    "    get_leagues()\n",
    "    \n",
    "    if df_leagues is not None and not df_leagues.empty:\n",
    "        print(\"\\nContenido de df_leagues:\")\n",
    "        print(df_leagues)\n",
    "    else:\n",
    "        print(\"df_leagues está vacío o no se ha creado correctamente.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99932e4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:02.174823Z",
     "iopub.status.busy": "2025-03-25T19:05:02.174661Z",
     "iopub.status.idle": "2025-03-25T19:05:02.182968Z",
     "shell.execute_reply": "2025-03-25T19:05:02.182593Z"
    },
    "papermill": {
     "duration": 0.014337,
     "end_time": "2025-03-25T19:05:02.183984",
     "exception": false,
     "start_time": "2025-03-25T19:05:02.169647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>name_en</th>\n",
       "      <th>iso_country_code</th>\n",
       "      <th>age_limit</th>\n",
       "      <th>division</th>\n",
       "      <th>season_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1184</td>\n",
       "      <td>Tercera RFEF - G4</td>\n",
       "      <td>None</td>\n",
       "      <td>ES</td>\n",
       "      <td>ADULT</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[1605, 3362, 4104]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>698</td>\n",
       "      <td>D. Honor Juvenil - G2</td>\n",
       "      <td>División Honor Juvenil - Grupo 2</td>\n",
       "      <td>ES</td>\n",
       "      <td>U19</td>\n",
       "      <td>32.0</td>\n",
       "      <td>[1626, 2399, 3303, 4024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1179</td>\n",
       "      <td>Segunda RFEF - G2</td>\n",
       "      <td>None</td>\n",
       "      <td>ES</td>\n",
       "      <td>ADULT</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[2382, 3259, 4019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1719</td>\n",
       "      <td>División de Honor - Araba</td>\n",
       "      <td>División de Honor - Araba</td>\n",
       "      <td>ES</td>\n",
       "      <td>ADULT</td>\n",
       "      <td>32.0</td>\n",
       "      <td>[2565]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992</td>\n",
       "      <td>Copa Vasca Cadete</td>\n",
       "      <td>Copa Vasca Cadete</td>\n",
       "      <td>ES</td>\n",
       "      <td>U16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2154</td>\n",
       "      <td>Liga Vasca Cadete</td>\n",
       "      <td>Liga Vasca Cadete</td>\n",
       "      <td>ES</td>\n",
       "      <td>U16</td>\n",
       "      <td>61.0</td>\n",
       "      <td>[3728, 3364, 4232]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                       name                           name_en  \\\n",
       "0  1184          Tercera RFEF - G4                              None   \n",
       "1   698      D. Honor Juvenil - G2  División Honor Juvenil - Grupo 2   \n",
       "2  1179          Segunda RFEF - G2                              None   \n",
       "3  1719  División de Honor - Araba         División de Honor - Araba   \n",
       "4  1992          Copa Vasca Cadete                 Copa Vasca Cadete   \n",
       "5  2154          Liga Vasca Cadete                 Liga Vasca Cadete   \n",
       "\n",
       "  iso_country_code age_limit  division                season_ids  \n",
       "0               ES     ADULT      13.0        [1605, 3362, 4104]  \n",
       "1               ES       U19      32.0  [1626, 2399, 3303, 4024]  \n",
       "2               ES     ADULT       6.0        [2382, 3259, 4019]  \n",
       "3               ES     ADULT      32.0                    [2565]  \n",
       "4               ES       U16       NaN                    [3001]  \n",
       "5               ES       U16      61.0        [3728, 3364, 4232]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0ea305",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:02.192744Z",
     "iopub.status.busy": "2025-03-25T19:05:02.192586Z",
     "iopub.status.idle": "2025-03-25T19:05:02.199713Z",
     "shell.execute_reply": "2025-03-25T19:05:02.199426Z"
    },
    "papermill": {
     "duration": 0.012339,
     "end_time": "2025-03-25T19:05:02.200609",
     "exception": false,
     "start_time": "2025-03-25T19:05:02.188270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>name_en</th>\n",
       "      <th>iso_country_code</th>\n",
       "      <th>age_limit</th>\n",
       "      <th>division</th>\n",
       "      <th>season_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1184</td>\n",
       "      <td>Tercera RFEF - G4</td>\n",
       "      <td>None</td>\n",
       "      <td>ES</td>\n",
       "      <td>ADULT</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1184</td>\n",
       "      <td>Tercera RFEF - G4</td>\n",
       "      <td>None</td>\n",
       "      <td>ES</td>\n",
       "      <td>ADULT</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1184</td>\n",
       "      <td>Tercera RFEF - G4</td>\n",
       "      <td>None</td>\n",
       "      <td>ES</td>\n",
       "      <td>ADULT</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>698</td>\n",
       "      <td>D. Honor Juvenil - G2</td>\n",
       "      <td>División Honor Juvenil - Grupo 2</td>\n",
       "      <td>ES</td>\n",
       "      <td>U19</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>698</td>\n",
       "      <td>D. Honor Juvenil - G2</td>\n",
       "      <td>División Honor Juvenil - Grupo 2</td>\n",
       "      <td>ES</td>\n",
       "      <td>U19</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>698</td>\n",
       "      <td>D. Honor Juvenil - G2</td>\n",
       "      <td>División Honor Juvenil - Grupo 2</td>\n",
       "      <td>ES</td>\n",
       "      <td>U19</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>698</td>\n",
       "      <td>D. Honor Juvenil - G2</td>\n",
       "      <td>División Honor Juvenil - Grupo 2</td>\n",
       "      <td>ES</td>\n",
       "      <td>U19</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1179</td>\n",
       "      <td>Segunda RFEF - G2</td>\n",
       "      <td>None</td>\n",
       "      <td>ES</td>\n",
       "      <td>ADULT</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1179</td>\n",
       "      <td>Segunda RFEF - G2</td>\n",
       "      <td>None</td>\n",
       "      <td>ES</td>\n",
       "      <td>ADULT</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1179</td>\n",
       "      <td>Segunda RFEF - G2</td>\n",
       "      <td>None</td>\n",
       "      <td>ES</td>\n",
       "      <td>ADULT</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1719</td>\n",
       "      <td>División de Honor - Araba</td>\n",
       "      <td>División de Honor - Araba</td>\n",
       "      <td>ES</td>\n",
       "      <td>ADULT</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992</td>\n",
       "      <td>Copa Vasca Cadete</td>\n",
       "      <td>Copa Vasca Cadete</td>\n",
       "      <td>ES</td>\n",
       "      <td>U16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2154</td>\n",
       "      <td>Liga Vasca Cadete</td>\n",
       "      <td>Liga Vasca Cadete</td>\n",
       "      <td>ES</td>\n",
       "      <td>U16</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2154</td>\n",
       "      <td>Liga Vasca Cadete</td>\n",
       "      <td>Liga Vasca Cadete</td>\n",
       "      <td>ES</td>\n",
       "      <td>U16</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2154</td>\n",
       "      <td>Liga Vasca Cadete</td>\n",
       "      <td>Liga Vasca Cadete</td>\n",
       "      <td>ES</td>\n",
       "      <td>U16</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                       name                           name_en  \\\n",
       "0  1184          Tercera RFEF - G4                              None   \n",
       "0  1184          Tercera RFEF - G4                              None   \n",
       "0  1184          Tercera RFEF - G4                              None   \n",
       "1   698      D. Honor Juvenil - G2  División Honor Juvenil - Grupo 2   \n",
       "1   698      D. Honor Juvenil - G2  División Honor Juvenil - Grupo 2   \n",
       "1   698      D. Honor Juvenil - G2  División Honor Juvenil - Grupo 2   \n",
       "1   698      D. Honor Juvenil - G2  División Honor Juvenil - Grupo 2   \n",
       "2  1179          Segunda RFEF - G2                              None   \n",
       "2  1179          Segunda RFEF - G2                              None   \n",
       "2  1179          Segunda RFEF - G2                              None   \n",
       "3  1719  División de Honor - Araba         División de Honor - Araba   \n",
       "4  1992          Copa Vasca Cadete                 Copa Vasca Cadete   \n",
       "5  2154          Liga Vasca Cadete                 Liga Vasca Cadete   \n",
       "5  2154          Liga Vasca Cadete                 Liga Vasca Cadete   \n",
       "5  2154          Liga Vasca Cadete                 Liga Vasca Cadete   \n",
       "\n",
       "  iso_country_code age_limit  division season_id  \n",
       "0               ES     ADULT      13.0      1605  \n",
       "0               ES     ADULT      13.0      3362  \n",
       "0               ES     ADULT      13.0      4104  \n",
       "1               ES       U19      32.0      1626  \n",
       "1               ES       U19      32.0      2399  \n",
       "1               ES       U19      32.0      3303  \n",
       "1               ES       U19      32.0      4024  \n",
       "2               ES     ADULT       6.0      2382  \n",
       "2               ES     ADULT       6.0      3259  \n",
       "2               ES     ADULT       6.0      4019  \n",
       "3               ES     ADULT      32.0      2565  \n",
       "4               ES       U16       NaN      3001  \n",
       "5               ES       U16      61.0      3728  \n",
       "5               ES       U16      61.0      3364  \n",
       "5               ES       U16      61.0      4232  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_league_seasons = df_leagues.explode('season_ids')\n",
    "df_league_seasons.rename(columns={'season_ids': 'season_id'}, inplace=True)\n",
    "df_league_seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be39e4ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:02.208076Z",
     "iopub.status.busy": "2025-03-25T19:05:02.207972Z",
     "iopub.status.idle": "2025-03-25T19:05:05.871285Z",
     "shell.execute_reply": "2025-03-25T19:05:05.871016Z"
    },
    "papermill": {
     "duration": 3.667981,
     "end_time": "2025-03-25T19:05:05.872184",
     "exception": false,
     "start_time": "2025-03-25T19:05:02.204203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1605, 'name': '21/22', 'season_group_name': '21/22', 'league_id': 1184, 'team_ids': [6638, 6830, 7411, 7419, 7680, 7740, 7752, 7753, 7774, 7791, 7826, 7830, 7894, 7953, 8022, 8181, 8199, 9848, 11025, 11026], 'start_year': 2021, 'end_year': 2022}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 3362, 'name': '23/24', 'season_group_name': '23/24', 'league_id': 1184, 'team_ids': [6638, 7411, 7680, 7740, 7752, 7753, 7791, 7826, 7894, 7953, 8022, 8181, 8542, 8598, 9848, 13048, 13054, 15447], 'start_year': 2023, 'end_year': 2024}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 4104, 'name': '24/25', 'season_group_name': '24/25', 'league_id': 1184, 'team_ids': [6638, 7411, 7740, 7752, 7753, 7791, 7826, 7878, 7894, 7953, 8181, 8542, 8598, 12966, 13048, 13051, 15447, 19626], 'start_year': 2024, 'end_year': 2025}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1626, 'name': '21/22', 'season_group_name': '21/22', 'league_id': 698, 'team_ids': [6375, 6376, 7724, 7778, 7895, 7955, 7986, 7998, 8138, 8200, 8242, 8283, 8292, 8293, 8505, 10421, 11120, 11121], 'start_year': 2021, 'end_year': 2022}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2399, 'name': '22/23', 'season_group_name': '22/23', 'league_id': 698, 'team_ids': [6375, 7724, 7778, 7892, 7998, 8138, 8200, 8242, 8283, 8292, 8293, 8460, 8505, 10421, 12221, 16019], 'start_year': 2022, 'end_year': 2023}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 3303, 'name': '23/24', 'season_group_name': '23/24', 'league_id': 698, 'team_ids': [3378, 6375, 7724, 7779, 7892, 7955, 7998, 8090, 8138, 8200, 8242, 8283, 8292, 8293, 8460, 9118, 12221, 26989, 26990], 'start_year': 2023, 'end_year': 2024}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 4024, 'name': '24/25', 'season_group_name': '24/25', 'league_id': 698, 'team_ids': [6375, 7724, 7760, 7778, 7892, 7955, 7998, 8138, 8200, 8239, 8242, 8283, 8292, 8293, 8460, 12159], 'start_year': 2024, 'end_year': 2025}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2382, 'name': '22/23', 'season_group_name': '22/23', 'league_id': 1179, 'team_ids': [7410, 7419, 7608, 7750, 7791, 7877, 7890, 8194, 9782, 9995, 10447, 11015, 11016, 11020, 11138, 11151, 13023, 15934, 15936, 15937], 'start_year': 2022, 'end_year': 2023}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 3259, 'name': '23/24', 'season_group_name': '23/24', 'league_id': 1179, 'team_ids': [6830, 7245, 7410, 7419, 7420, 7608, 7750, 7890, 7989, 8194, 9995, 11016, 11019, 11151, 13020, 13797, 15934, 16301], 'start_year': 2023, 'end_year': 2024}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 4019, 'name': '24/25', 'season_group_name': '24/25', 'league_id': 1179, 'team_ids': [7410, 7419, 7420, 7608, 7680, 7750, 7890, 7989, 8194, 8509, 10448, 11155, 12987, 13797, 15934, 15936, 16285, 16301], 'start_year': 2024, 'end_year': 2025}\n",
      "{'id': 2565, 'name': '22/23', 'season_group_name': '22/23', 'league_id': 1719, 'team_ids': [7942, 9845, 11025, 15447, 16683, 16994, 17068, 17236, 17383, 17764, 17847, 17925, 18300, 18508, 18632, 18902, 19160, 19323, 19626], 'start_year': 2022, 'end_year': 2023}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 3001, 'name': '22/23', 'season_group_name': '22/23', 'league_id': 1992, 'team_ids': [7757, 7780, 7893, 7897, 7898, 7939, 8019, 8197], 'start_year': 2022, 'end_year': 2023}\n",
      "{'id': 3728, 'name': '22/23', 'season_group_name': '22/23', 'league_id': 2154, 'team_ids': [7749, 7757, 7780, 7893, 7897, 7898, 7939, 7951, 8019, 8024, 8131, 8137, 8197, 8282, 8323, 8359, 11950, 12120, 16990], 'start_year': 2022, 'end_year': 2023}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 3364, 'name': '23/24', 'season_group_name': '23/24', 'league_id': 2154, 'team_ids': [7749, 7757, 7780, 7893, 7897, 7898, 7939, 7951, 8019, 8131, 8197, 8241, 8282, 8323, 9818, 12120, 12139, 13081], 'start_year': 2023, 'end_year': 2024}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 4232, 'name': '24/25', 'season_group_name': '24/25', 'league_id': 2154, 'team_ids': [7749, 7757, 7780, 7893, 7897, 7898, 7939, 8019, 8131, 8137, 8197, 8241, 8282, 8996, 12120, 12139, 12143, 12735], 'start_year': 2024, 'end_year': 2025}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_id</th>\n",
       "      <th>name</th>\n",
       "      <th>season_group_name</th>\n",
       "      <th>league_id</th>\n",
       "      <th>team_ids</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1605</td>\n",
       "      <td>21/22</td>\n",
       "      <td>21/22</td>\n",
       "      <td>1184</td>\n",
       "      <td>[6638, 6830, 7411, 7419, 7680, 7740, 7752, 775...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3362</td>\n",
       "      <td>23/24</td>\n",
       "      <td>23/24</td>\n",
       "      <td>1184</td>\n",
       "      <td>[6638, 7411, 7680, 7740, 7752, 7753, 7791, 782...</td>\n",
       "      <td>2023</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4104</td>\n",
       "      <td>24/25</td>\n",
       "      <td>24/25</td>\n",
       "      <td>1184</td>\n",
       "      <td>[6638, 7411, 7740, 7752, 7753, 7791, 7826, 787...</td>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1626</td>\n",
       "      <td>21/22</td>\n",
       "      <td>21/22</td>\n",
       "      <td>698</td>\n",
       "      <td>[6375, 6376, 7724, 7778, 7895, 7955, 7986, 799...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2399</td>\n",
       "      <td>22/23</td>\n",
       "      <td>22/23</td>\n",
       "      <td>698</td>\n",
       "      <td>[6375, 7724, 7778, 7892, 7998, 8138, 8200, 824...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3303</td>\n",
       "      <td>23/24</td>\n",
       "      <td>23/24</td>\n",
       "      <td>698</td>\n",
       "      <td>[3378, 6375, 7724, 7779, 7892, 7955, 7998, 809...</td>\n",
       "      <td>2023</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4024</td>\n",
       "      <td>24/25</td>\n",
       "      <td>24/25</td>\n",
       "      <td>698</td>\n",
       "      <td>[6375, 7724, 7760, 7778, 7892, 7955, 7998, 813...</td>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2382</td>\n",
       "      <td>22/23</td>\n",
       "      <td>22/23</td>\n",
       "      <td>1179</td>\n",
       "      <td>[7410, 7419, 7608, 7750, 7791, 7877, 7890, 819...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3259</td>\n",
       "      <td>23/24</td>\n",
       "      <td>23/24</td>\n",
       "      <td>1179</td>\n",
       "      <td>[6830, 7245, 7410, 7419, 7420, 7608, 7750, 789...</td>\n",
       "      <td>2023</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4019</td>\n",
       "      <td>24/25</td>\n",
       "      <td>24/25</td>\n",
       "      <td>1179</td>\n",
       "      <td>[7410, 7419, 7420, 7608, 7680, 7750, 7890, 798...</td>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2565</td>\n",
       "      <td>22/23</td>\n",
       "      <td>22/23</td>\n",
       "      <td>1719</td>\n",
       "      <td>[7942, 9845, 11025, 15447, 16683, 16994, 17068...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3001</td>\n",
       "      <td>22/23</td>\n",
       "      <td>22/23</td>\n",
       "      <td>1992</td>\n",
       "      <td>[7757, 7780, 7893, 7897, 7898, 7939, 8019, 8197]</td>\n",
       "      <td>2022</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3728</td>\n",
       "      <td>22/23</td>\n",
       "      <td>22/23</td>\n",
       "      <td>2154</td>\n",
       "      <td>[7749, 7757, 7780, 7893, 7897, 7898, 7939, 795...</td>\n",
       "      <td>2022</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3364</td>\n",
       "      <td>23/24</td>\n",
       "      <td>23/24</td>\n",
       "      <td>2154</td>\n",
       "      <td>[7749, 7757, 7780, 7893, 7897, 7898, 7939, 795...</td>\n",
       "      <td>2023</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4232</td>\n",
       "      <td>24/25</td>\n",
       "      <td>24/25</td>\n",
       "      <td>2154</td>\n",
       "      <td>[7749, 7757, 7780, 7893, 7897, 7898, 7939, 801...</td>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season_id   name season_group_name  league_id  \\\n",
       "0       1605  21/22             21/22       1184   \n",
       "0       3362  23/24             23/24       1184   \n",
       "0       4104  24/25             24/25       1184   \n",
       "0       1626  21/22             21/22        698   \n",
       "0       2399  22/23             22/23        698   \n",
       "0       3303  23/24             23/24        698   \n",
       "0       4024  24/25             24/25        698   \n",
       "0       2382  22/23             22/23       1179   \n",
       "0       3259  23/24             23/24       1179   \n",
       "0       4019  24/25             24/25       1179   \n",
       "0       2565  22/23             22/23       1719   \n",
       "0       3001  22/23             22/23       1992   \n",
       "0       3728  22/23             22/23       2154   \n",
       "0       3364  23/24             23/24       2154   \n",
       "0       4232  24/25             24/25       2154   \n",
       "\n",
       "                                            team_ids  start_year  end_year  \n",
       "0  [6638, 6830, 7411, 7419, 7680, 7740, 7752, 775...        2021      2022  \n",
       "0  [6638, 7411, 7680, 7740, 7752, 7753, 7791, 782...        2023      2024  \n",
       "0  [6638, 7411, 7740, 7752, 7753, 7791, 7826, 787...        2024      2025  \n",
       "0  [6375, 6376, 7724, 7778, 7895, 7955, 7986, 799...        2021      2022  \n",
       "0  [6375, 7724, 7778, 7892, 7998, 8138, 8200, 824...        2022      2023  \n",
       "0  [3378, 6375, 7724, 7779, 7892, 7955, 7998, 809...        2023      2024  \n",
       "0  [6375, 7724, 7760, 7778, 7892, 7955, 7998, 813...        2024      2025  \n",
       "0  [7410, 7419, 7608, 7750, 7791, 7877, 7890, 819...        2022      2023  \n",
       "0  [6830, 7245, 7410, 7419, 7420, 7608, 7750, 789...        2023      2024  \n",
       "0  [7410, 7419, 7420, 7608, 7680, 7750, 7890, 798...        2024      2025  \n",
       "0  [7942, 9845, 11025, 15447, 16683, 16994, 17068...        2022      2023  \n",
       "0   [7757, 7780, 7893, 7897, 7898, 7939, 8019, 8197]        2022      2023  \n",
       "0  [7749, 7757, 7780, 7893, 7897, 7898, 7939, 795...        2022      2023  \n",
       "0  [7749, 7757, 7780, 7893, 7897, 7898, 7939, 795...        2023      2024  \n",
       "0  [7749, 7757, 7780, 7893, 7897, 7898, 7939, 801...        2024      2025  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seasons_teams = pd.DataFrame()\n",
    "\n",
    "for indice_fila, fila in df_league_seasons.iterrows():\n",
    "    try:\n",
    "      endpoint = '/seasons/' + str(fila['season_id'])\n",
    "      season = getResults(endpoint)\n",
    "\n",
    "      if(season['result']):\n",
    "        print(season['result'])\n",
    "\n",
    "        df_season = json_normalize(season['result'])\n",
    "        df_seasons_teams = pd.concat([df_seasons_teams,df_season])\n",
    "\n",
    "        \n",
    "    except Exception as error:\n",
    "      pass\n",
    "\n",
    "df_seasons_teams.rename(columns={'id': 'season_id'}, inplace=True)\n",
    "df_seasons_teams.drop_duplicates(subset=['league_id','season_id'], inplace=True)\n",
    "df_seasons_teams.to_parquet(os.path.join(BASE_PATH, 'seasons_teams.parquet'), index=False)\n",
    "\n",
    "df_seasons_teams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b869d9",
   "metadata": {
    "papermill": {
     "duration": 0.003506,
     "end_time": "2025-03-25T19:05:05.879907",
     "exception": false,
     "start_time": "2025-03-25T19:05:05.876401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"color:yelow;\">PONER LA LEAGUE_ID QUE DESEO EXTRAER</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4fe81c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:05.888218Z",
     "iopub.status.busy": "2025-03-25T19:05:05.888058Z",
     "iopub.status.idle": "2025-03-25T19:05:05.890702Z",
     "shell.execute_reply": "2025-03-25T19:05:05.890462Z"
    },
    "papermill": {
     "duration": 0.008021,
     "end_time": "2025-03-25T19:05:05.891486",
     "exception": false,
     "start_time": "2025-03-25T19:05:05.883465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season IDs para la liga 2135: []\n"
     ]
    }
   ],
   "source": [
    "# Establecer la Liga que deseas extraer\n",
    "league_id = 2135\n",
    "\n",
    "# Extraer solamente las season_id relacionadas con la league_id\n",
    "season_resultantes = df_seasons_teams[df_seasons_teams['league_id'] == league_id]['season_id'].unique().tolist()\n",
    "\n",
    "print(f\"Season IDs para la liga {league_id}: {season_resultantes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c3588b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:05.899508Z",
     "iopub.status.busy": "2025-03-25T19:05:05.899380Z",
     "iopub.status.idle": "2025-03-25T19:05:05.906074Z",
     "shell.execute_reply": "2025-03-25T19:05:05.905827Z"
    },
    "papermill": {
     "duration": 0.011723,
     "end_time": "2025-03-25T19:05:05.906861",
     "exception": false,
     "start_time": "2025-03-25T19:05:05.895138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos procesados para la liga 2135:\n",
      "Empty DataFrame\n",
      "Columns: [season_id, name, season_group_name, league_id, team_id, start_year, end_year]\n",
      "Index: []\n",
      "Número de filas en el DataFrame: 0\n",
      "\n",
      "El DataFrame 'df_teams_2135' ha sido creado y guardado.\n",
      "Número total de Equipos en df_teams_2135: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_league_data(df_seasons_teams, league_id):\n",
    "    \"\"\"\n",
    "    Procesa los datos de una liga específica.\n",
    "    \n",
    "    :param df_seasons_teams: DataFrame con los datos de temporadas y equipos\n",
    "    :param league_id: ID de la liga a procesar\n",
    "    :return: Tupla con el nombre del DataFrame y el DataFrame procesado\n",
    "    \"\"\"\n",
    "    # Filtrar solo la liga especificada\n",
    "    df_filtered = df_seasons_teams[df_seasons_teams['league_id'] == league_id]\n",
    "    \n",
    "    # Realizar las operaciones en los datos filtrados\n",
    "    df_teams = df_filtered.explode('team_ids')\n",
    "    df_teams.rename(columns={'id': 'season_id', 'team_ids': 'team_id'}, inplace=True)\n",
    "    df_teams.drop_duplicates(subset=['team_id', 'league_id', 'season_id'], inplace=True)\n",
    "    \n",
    "    # Crear un nombre dinámico para el DataFrame\n",
    "    df_name = f\"df_teams_{league_id}\"\n",
    "    \n",
    "    # Guardar el DataFrame en un archivo Parquet\n",
    "    os.makedirs(BASE_PATH, exist_ok=True)\n",
    "    df_teams.to_parquet(os.path.join(BASE_PATH, f'teams_league_{league_id}.parquet'), index=False)\n",
    "    \n",
    "    print(f\"Datos procesados para la liga {league_id}:\")\n",
    "    print(df_teams.head())\n",
    "    \n",
    "    # Contar el número de filas\n",
    "    num_rows = len(df_teams)\n",
    "    print(f\"Número de filas en el DataFrame: {num_rows}\")\n",
    "    \n",
    "    return df_name, df_teams\n",
    "\n",
    "# Uso de la función\n",
    "df_name, df_processed = process_league_data(df_seasons_teams, league_id)\n",
    "\n",
    "# El DataFrame procesado ahora está disponible con un nombre dinámico\n",
    "globals()[df_name] = df_processed\n",
    "\n",
    "print(f\"\\nEl DataFrame '{df_name}' ha sido creado y guardado.\")\n",
    "print(f\"Número total de Equipos en {df_name}: {len(globals()[df_name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "548a4c5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:05.914654Z",
     "iopub.status.busy": "2025-03-25T19:05:05.914521Z",
     "iopub.status.idle": "2025-03-25T19:05:05.916487Z",
     "shell.execute_reply": "2025-03-25T19:05:05.916235Z"
    },
    "papermill": {
     "duration": 0.006696,
     "end_time": "2025-03-25T19:05:05.917234",
     "exception": false,
     "start_time": "2025-03-25T19:05:05.910538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_teams = pd.DataFrame()\n",
    "df_teams_players = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "921c9a70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:05.925531Z",
     "iopub.status.busy": "2025-03-25T19:05:05.925345Z",
     "iopub.status.idle": "2025-03-25T19:05:05.928840Z",
     "shell.execute_reply": "2025-03-25T19:05:05.928582Z"
    },
    "papermill": {
     "duration": 0.008572,
     "end_time": "2025-03-25T19:05:05.929609",
     "exception": false,
     "start_time": "2025-03-25T19:05:05.921037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesamiento completado. df_teams contiene 0 filas.\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame vacío para acumular todos los datos\n",
    "df_all_team_players = pd.DataFrame()\n",
    "\n",
    "for indice_fila, fila in df_seasons_teams.iterrows():\n",
    "    if fila['season_id'] in season_resultantes:  # Solo procesa las temporadas en season_resultantes\n",
    "        try:\n",
    "            teams = getResults('/teams', {'season': fila['season_id']})\n",
    "            \n",
    "            if teams['result']:\n",
    "                df_team = json_normalize(teams['result'])\n",
    "                \n",
    "                df_team['season_id'] = fila['season_id']\n",
    "                df_team.rename(columns={'id': 'team_id'}, inplace=True)\n",
    "                \n",
    "                df_teams = pd.concat([df_teams, df_team])\n",
    "                \n",
    "                # Procesar players\n",
    "                df_team_players = df_team.explode('player_ids')\n",
    "                df_team_players.rename(columns={'id': 'team_id', 'player_ids': 'player_id'}, inplace=True)\n",
    "                \n",
    "                # Acumular en el DataFrame general\n",
    "                df_all_team_players = pd.concat([df_all_team_players, df_team_players], ignore_index=True)\n",
    "                print(f\"✓ Temporada {fila['season_id']}: {len(df_team_players)} registros procesados\")\n",
    "                \n",
    "        except Exception as error:\n",
    "            print(f\"❌ Error procesando temporada {fila['season_id']}: {error}\")\n",
    "\n",
    "\n",
    "print(f\"Procesamiento completado. df_teams contiene {len(df_teams)} filas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11fe12e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:05.938177Z",
     "iopub.status.busy": "2025-03-25T19:05:05.938030Z",
     "iopub.status.idle": "2025-03-25T19:05:05.940363Z",
     "shell.execute_reply": "2025-03-25T19:05:05.940142Z"
    },
    "papermill": {
     "duration": 0.0077,
     "end_time": "2025-03-25T19:05:05.941091",
     "exception": false,
     "start_time": "2025-03-25T19:05:05.933391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be61faa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:05.949282Z",
     "iopub.status.busy": "2025-03-25T19:05:05.949146Z",
     "iopub.status.idle": "2025-03-25T19:05:05.951007Z",
     "shell.execute_reply": "2025-03-25T19:05:05.950780Z"
    },
    "papermill": {
     "duration": 0.006862,
     "end_time": "2025-03-25T19:05:05.951717",
     "exception": false,
     "start_time": "2025-03-25T19:05:05.944855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(df_teams))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a2b4ff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:05.959599Z",
     "iopub.status.busy": "2025-03-25T19:05:05.959388Z",
     "iopub.status.idle": "2025-03-25T19:05:05.961878Z",
     "shell.execute_reply": "2025-03-25T19:05:05.961677Z"
    },
    "papermill": {
     "duration": 0.007379,
     "end_time": "2025-03-25T19:05:05.962613",
     "exception": false,
     "start_time": "2025-03-25T19:05:05.955234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado en: /Users/imac/Programas/Datos_API_Bepro/Alaves_Github/BePro/documentacion/../data_backup/archivos_parquet/Liga Nacional Juvenil - Grupo 4/teams_league_2135.parquet\n"
     ]
    }
   ],
   "source": [
    "# Eliminar duplicados y guardar el archivo sin el season_id en el nombre\n",
    "df_teams.drop_duplicates(subset=['team_id', 'season_id'], inplace=True)\n",
    "# Guardar el DataFrame acumulado en un único archivo Parquet\n",
    "output_path = os.path.join(BASE_PATH, f'teams_league_{league_id}.parquet')\n",
    "df_teams.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"Archivo guardado en: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42912962",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f18451c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T19:05:05.970090Z",
     "iopub.status.busy": "2025-03-25T19:05:05.969993Z",
     "iopub.status.idle": "2025-03-25T19:05:06.561836Z",
     "shell.execute_reply": "2025-03-25T19:05:06.561415Z"
    },
    "papermill": {
     "duration": 0.596342,
     "end_time": "2025-03-25T19:05:06.562535",
     "exception": true,
     "start_time": "2025-03-25T19:05:05.966193",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'player_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_teams_players \u001b[38;5;241m=\u001b[39m df_teams\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_ids\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m df_teams_players\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_id\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:9846\u001b[0m, in \u001b[0;36mDataFrame.explode\u001b[0;34m(self, column, ignore_index)\u001b[0m\n\u001b[1;32m   9844\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   9845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 9846\u001b[0m     result \u001b[38;5;241m=\u001b[39m df[columns[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mexplode()\n\u001b[1;32m   9847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   9848\u001b[0m     mylen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m (is_list_like(x) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'player_ids'"
     ]
    }
   ],
   "source": [
    "df_teams_players = df_teams.explode('player_ids')\n",
    "df_teams_players.rename(columns={'id':'team_id','player_ids': 'player_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89830b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:03:43.732110Z",
     "iopub.status.busy": "2024-11-12T17:03:43.731995Z",
     "iopub.status.idle": "2024-11-12T17:03:43.733690Z",
     "shell.execute_reply": "2024-11-12T17:03:43.733487Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(df_teams_players))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7191b7ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:03:43.742459Z",
     "iopub.status.busy": "2024-11-12T17:03:43.742332Z",
     "iopub.status.idle": "2024-11-12T17:03:43.746804Z",
     "shell.execute_reply": "2024-11-12T17:03:43.746542Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_teams_players.drop_duplicates(subset=['player_id','team_id','season_id'], inplace=True)\n",
    "df_teams_players.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2ad731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:03:43.807941Z",
     "iopub.status.busy": "2024-11-12T17:03:43.807348Z",
     "iopub.status.idle": "2024-11-12T17:03:43.814379Z",
     "shell.execute_reply": "2024-11-12T17:03:43.813610Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Guardar el DataFrame acumulado en un único archivo Parquet\n",
    "output_path = os.path.join(BASE_PATH, f'players_league_{league_id}.parquet')\n",
    "df_teams_players.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"Archivo guardado en: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c785980d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:03:43.826787Z",
     "iopub.status.busy": "2024-11-12T17:03:43.826634Z",
     "iopub.status.idle": "2024-11-12T17:04:14.356641Z",
     "shell.execute_reply": "2024-11-12T17:04:14.356337Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(df_teams_players) > 0:\n",
    "    names_team_players = pd.DataFrame()\n",
    "    total_jugadores = len(df_teams_players)\n",
    "    jugadores_procesados = 0\n",
    "    batch_size = 50  # Procesar jugadores en lotes\n",
    "    \n",
    "    # Agrupar por equipo y temporada para procesar en lotes\n",
    "    for (team_id, season_id), grupo in df_teams_players.groupby(['team_id', 'season_id']):\n",
    "        try:\n",
    "            # Llamada única a la API por equipo y temporada\n",
    "            team_players = getResults('/players', {\n",
    "                'team': team_id,\n",
    "                'season': season_id,\n",
    "                'limit': 200  # Aumentar límite para obtener más jugadores por llamada\n",
    "            })\n",
    "            \n",
    "            if team_players['result']:\n",
    "                ed = json_normalize(team_players['result'])\n",
    "                if not ed.empty:\n",
    "                    ed['team_id'] = team_id\n",
    "                    ed['season_id'] = season_id\n",
    "                    ed.rename(columns={'id': 'player_id'}, inplace=True)\n",
    "                    \n",
    "                    # Convertir tipos de datos\n",
    "                    ed['team_id'] = ed['team_id'].astype(int)\n",
    "                    ed['season_id'] = ed['season_id'].astype(int)\n",
    "                    ed['player_id'] = ed['player_id'].astype(float)\n",
    "                    \n",
    "                    names_team_players = pd.concat([names_team_players, ed], ignore_index=True)\n",
    "                    jugadores_procesados += len(ed)\n",
    "                    \n",
    "                    # Mostrar progreso cada 100 jugadores\n",
    "                    if jugadores_procesados % 100 == 0:\n",
    "                        print(f\"Progreso: {jugadores_procesados} jugadores procesados\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error en equipo {team_id}, temporada {season_id}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Verificación y guardado\n",
    "    if not names_team_players.empty:\n",
    "        names_team_players.drop_duplicates(subset=['player_id', 'team_id', 'season_id'], inplace=True)\n",
    "        output_path = os.path.join(BASE_PATH, f'names_players_league_{league_id}.parquet')\n",
    "        names_team_players.to_parquet(output_path, index=False)\n",
    "        print(f\"\\nCompletado: {len(names_team_players)} jugadores guardados en {output_path}\")\n",
    "    else:\n",
    "        print(\"❌ No se recopilaron datos\")\n",
    "else:\n",
    "    print(\"No hay jugadores para procesar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd6ac25",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_teams_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0898f226",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "names_team_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62be8e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:04:14.397802Z",
     "iopub.status.busy": "2024-11-12T17:04:14.397461Z",
     "iopub.status.idle": "2024-11-12T17:04:14.400334Z",
     "shell.execute_reply": "2024-11-12T17:04:14.399985Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(names_team_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb36033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:04:14.439719Z",
     "iopub.status.busy": "2024-11-12T17:04:14.439575Z",
     "iopub.status.idle": "2024-11-12T17:04:17.015724Z",
     "shell.execute_reply": "2024-11-12T17:04:17.015168Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import os\n",
    "\n",
    "if len(df_league_seasons) > 0:\n",
    "    # Inicializamos los DataFrames\n",
    "    df_matches = pd.DataFrame()  # DataFrame para todos los partidos\n",
    "    df_matches_new = pd.DataFrame()  # DataFrame para los partidos nuevos\n",
    "    total_seasons = len(season_resultantes)\n",
    "    processed_seasons = 0\n",
    "    \n",
    "    # Verificar si existe el archivo parquet y cargarlo\n",
    "    output_path = os.path.join(BASE_PATH, f'matches_league_{league_id}.parquet')\n",
    "    existing_matches = pd.DataFrame()\n",
    "    if os.path.exists(output_path):\n",
    "        existing_matches = pd.read_parquet(output_path)\n",
    "        print(f\"Archivo existente cargado con {len(existing_matches)} partidos\")\n",
    "        existing_match_ids = set(existing_matches['match_id'])\n",
    "    else:\n",
    "        existing_match_ids = set()\n",
    "        print(\"No se encontró archivo existente. Se procesarán todos los partidos.\")\n",
    "\n",
    "    for indice_fila, fila in df_league_seasons.iterrows():\n",
    "        if fila['season_id'] in season_resultantes:\n",
    "            processed_seasons += 1\n",
    "            print(f'\\nProcesando Season {fila.season_id} ({processed_seasons}/{total_seasons})')\n",
    "            \n",
    "            try:\n",
    "                # Llama a la API pasando 'season_id'\n",
    "                matches = getResults('/matches', {'season': fila['season_id']})\n",
    "                \n",
    "                if matches['result']:\n",
    "                    df_season_matches = json_normalize(matches['result'])\n",
    "                    print(f\"Cantidad de partidos en la temporada {fila['season_id']}: {len(df_season_matches)}\")\n",
    "                    \n",
    "                    # Renombrar columnas\n",
    "                    df_season_matches.rename(columns={\n",
    "                        'id': 'match_id',\n",
    "                        'home_team.id': 'home_team_id',\n",
    "                        'away_team.id': 'away_team_id',\n",
    "                        'detail_match_result.home_team_score': 'home_team_score',\n",
    "                        'detail_match_result.away_team_score': 'away_team_score',\n",
    "                        'round.id': 'round_id',\n",
    "                        'round.name': 'round_name',\n",
    "                        'season.id': 'season_id',\n",
    "                        'season.name': 'season_name',\n",
    "                        'season.season_group_name': 'season_group_name',\n",
    "                        'season.league_id': 'league_id',\n",
    "                        'home_team.name': 'home_team_name',\n",
    "                        'home_team.name_en': 'home_team_name_en',\n",
    "                        'home_team.iso_country_code': 'home_team_iso_country_code',\n",
    "                        'away_team.name': 'away_team_name',\n",
    "                        'away_team.name_en': 'away_team_name_en',\n",
    "                        'away_team.iso_country_code': 'away_team_iso_country_code',\n",
    "                        'venue.id': 'venue_id',\n",
    "                        'venue.display_name': 'venue_display_name',\n",
    "                        'venue.ground_width': 'venue_ground_width',\n",
    "                        'venue.ground_height': 'venue_ground_height'\n",
    "                    }, inplace=True)\n",
    "                    \n",
    "                    # Filtrar solo los partidos nuevos\n",
    "                    new_matches = df_season_matches[~df_season_matches['match_id'].isin(existing_match_ids)]\n",
    "                    print(f\"Partidos nuevos encontrados en esta temporada: {len(new_matches)}\")\n",
    "                    \n",
    "                    # Agregar los nuevos partidos a ambos DataFrames\n",
    "                    df_matches = pd.concat([df_matches, df_season_matches], ignore_index=True)\n",
    "                    df_matches_new = pd.concat([df_matches_new, new_matches], ignore_index=True)\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"No se encontraron partidos para la temporada {fila['season_id']}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando temporada {fila['season_id']}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    # Verificar duplicados y guardar los partidos\n",
    "    if len(df_matches) > 0:\n",
    "        # Eliminar posibles duplicados\n",
    "        df_matches.drop_duplicates(subset=['match_id'], inplace=True)\n",
    "        df_matches_new.drop_duplicates(subset=['match_id'], inplace=True)\n",
    "        \n",
    "        # Mostrar resumen\n",
    "        print(\"\\nResumen de partidos por temporada:\")\n",
    "        season_counts = df_matches['season_id'].value_counts()\n",
    "        for season_id, count in season_counts.items():\n",
    "            print(f\"Temporada {season_id}: {count} partidos\")\n",
    "        \n",
    "        # Si hay partidos nuevos, actualizar el archivo\n",
    "        if len(df_matches_new) > 0:\n",
    "            # Combinar partidos existentes con nuevos\n",
    "            if len(existing_matches) > 0:\n",
    "                df_matches = pd.concat([existing_matches, df_matches_new], ignore_index=True)\n",
    "            else:\n",
    "                df_matches = df_matches_new\n",
    "                \n",
    "            # Guardar en Parquet\n",
    "            df_matches.to_parquet(output_path, index=False)\n",
    "            print(f\"\\nSe han encontrado {len(df_matches_new)} partidos nuevos\")\n",
    "            print(f\"Se ha actualizado el archivo con un total de {len(df_matches)} partidos en: {output_path}\")\n",
    "        else:\n",
    "            print(\"\\nNo se encontraron partidos nuevos para agregar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6baebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:04:17.037733Z",
     "iopub.status.busy": "2024-11-12T17:04:17.037499Z",
     "iopub.status.idle": "2024-11-12T17:04:17.049173Z",
     "shell.execute_reply": "2024-11-12T17:04:17.048773Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b932dc93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:04:17.063406Z",
     "iopub.status.busy": "2024-11-12T17:04:17.063249Z",
     "iopub.status.idle": "2024-11-12T17:04:17.065863Z",
     "shell.execute_reply": "2024-11-12T17:04:17.065571Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convertStringToFecha(start_time):\n",
    "  try:\n",
    "    fecha = start_time\n",
    "    fecha = fecha.split(\" \")[0]\n",
    "    fecha = fecha.split(\"-\")[2] + '/' + fecha.split(\"-\")[1] + '/' + fecha.split(\"-\")[0]\n",
    "  except:\n",
    "    fecha=''\n",
    "  return fecha\n",
    "\n",
    "def convertStringToHora(start_time):\n",
    "  try:\n",
    "    hora = start_time\n",
    "    hora = hora.split(\" \")[1]\n",
    "    hora = hora.split(\":\")[0] + ':' + hora.split(\":\")[1] + ' hs'\n",
    "  except:\n",
    "    hora=''\n",
    "  return hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1cb25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:04:17.077650Z",
     "iopub.status.busy": "2024-11-12T17:04:17.077502Z",
     "iopub.status.idle": "2024-11-12T17:07:09.024166Z",
     "shell.execute_reply": "2024-11-12T17:07:09.023885Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def process_single_match(match_info, existing_ids=None):\n",
    "    if existing_ids is not None and match_info['match_id'] in existing_ids:\n",
    "        return None\n",
    "\n",
    "    df_events = pd.DataFrame()\n",
    "    offset = 0\n",
    "    total = 1000\n",
    "    intentos = 0\n",
    "    max_intentos = 3\n",
    "\n",
    "    while total == 1000:\n",
    "        try:\n",
    "            event_data = getResults(\n",
    "                f\"/matches/{match_info['match_id']}/event_data\",\n",
    "                {'limit': 5000, 'offset': offset}\n",
    "            )\n",
    "\n",
    "            if 'detail' in event_data and event_data['detail'] in ['Match is not analyzed', 'Not found.']:\n",
    "                break\n",
    "\n",
    "            if not event_data['result']:\n",
    "                break\n",
    "\n",
    "            ed = json_normalize(event_data['result'])\n",
    "            total = len(ed)\n",
    "\n",
    "            if total > 0:\n",
    "                ed['match_id'] = match_info['match_id']\n",
    "                ed['season_id'] = match_info['season_id']\n",
    "\n",
    "                if 'event_types' in ed.columns:\n",
    "                    base_cols = ed.drop('event_types', axis=1)\n",
    "                    event_type_cols = ed['event_types'].apply(\n",
    "                        lambda x: pd.Series(x[0]) if x else pd.Series()\n",
    "                    ).add_suffix('_event_type')\n",
    "                    ed_expanded = pd.concat([base_cols, event_type_cols], axis=1)\n",
    "                else:\n",
    "                    ed_expanded = ed\n",
    "\n",
    "                df_events = pd.concat([df_events, ed_expanded], ignore_index=True)\n",
    "                offset += 1000\n",
    "\n",
    "            time.sleep(0.5)\n",
    "            intentos = 0\n",
    "\n",
    "        except Exception as e:\n",
    "            intentos += 1\n",
    "            if intentos >= max_intentos:\n",
    "                print(f\"Error máximo alcanzado para partido {match_info['match_id']}: {str(e)}\")\n",
    "                break\n",
    "            time.sleep(2)\n",
    "\n",
    "    return df_events\n",
    "\n",
    "def process_new_matches(df_matches_new, season_resultantes, league_id, batch_size=10):\n",
    "    output_path = os.path.join(BASE_PATH, f'events_league_{league_id}.parquet')\n",
    "    \n",
    "    # Inicializar DataFrame global y cargar datos existentes\n",
    "    existing_ids = set()\n",
    "    if os.path.exists(output_path):\n",
    "        try:\n",
    "            df_event_data = pd.read_parquet(output_path)\n",
    "            first_column = df_event_data.columns[0]\n",
    "            existing_ids = set(df_event_data[first_column].unique())\n",
    "            print(f\"Archivo existente encontrado con {len(existing_ids)} registros únicos\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al leer archivo existente: {str(e)}\")\n",
    "            df_event_data = pd.DataFrame()\n",
    "    else:\n",
    "        df_event_data = pd.DataFrame()\n",
    "\n",
    "    # Filtrar solo los partidos nuevos que estén en las temporadas seleccionadas\n",
    "    matches_to_process = df_matches_new[\n",
    "        df_matches_new['season_id'].isin(season_resultantes)\n",
    "    ]\n",
    "\n",
    "    if len(matches_to_process) == 0:\n",
    "        print(\"No hay nuevos partidos para procesar\")\n",
    "        return df_event_data\n",
    "\n",
    "    print(f\"Procesando {len(matches_to_process)} partidos nuevos\")\n",
    "\n",
    "    total_batches = (len(matches_to_process) + batch_size - 1) // batch_size\n",
    "\n",
    "    for batch_idx in range(total_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(matches_to_process))\n",
    "        batch = matches_to_process.iloc[start_idx:end_idx]\n",
    "        \n",
    "        print(f\"\\nProcesando lote {batch_idx + 1}/{total_batches}\")\n",
    "        \n",
    "        new_events = pd.DataFrame()\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            futures = {\n",
    "                executor.submit(\n",
    "                    process_single_match, \n",
    "                    row.to_dict(), \n",
    "                    existing_ids\n",
    "                ): row['match_id'] \n",
    "                for _, row in batch.iterrows()\n",
    "            }\n",
    "            \n",
    "            for future in tqdm(\n",
    "                concurrent.futures.as_completed(futures), \n",
    "                total=len(futures),\n",
    "                desc=\"Progreso del lote\"\n",
    "            ):\n",
    "                try:\n",
    "                    match_events = future.result()\n",
    "                    if match_events is not None and not match_events.empty:\n",
    "                        first_column = match_events.columns[0]\n",
    "                        new_records = match_events[~match_events[first_column].isin(existing_ids)]\n",
    "                        if not new_records.empty:\n",
    "                            new_events = pd.concat([new_events, new_records], ignore_index=True)\n",
    "                            existing_ids.update(new_records[first_column].unique())\n",
    "                except Exception as e:\n",
    "                    print(f\"Error procesando partido: {str(e)}\")\n",
    "\n",
    "        if not new_events.empty:\n",
    "            df_event_data = pd.concat([df_event_data, new_events], ignore_index=True)\n",
    "            try:\n",
    "                df_event_data.to_parquet(output_path, index=False)\n",
    "                print(f\"Progreso guardado: {len(df_event_data)} eventos totales\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error al guardar progreso: {str(e)}\")\n",
    "\n",
    "    return df_event_data\n",
    "\n",
    "# Uso del código\n",
    "try:\n",
    "    # Asumiendo que df_matches_new ya contiene solo los partidos nuevos\n",
    "    df_event_data = process_new_matches(df_matches_new, season_resultantes, league_id)\n",
    "\n",
    "    if len(df_event_data) > 0:\n",
    "        print(\"\\nProcesamiento completado con éxito:\")\n",
    "        print(f\"Total de eventos acumulados: {len(df_event_data)}\")\n",
    "        print(f\"Eventos guardados en: {os.path.join(BASE_PATH, f'events_league_{league_id}.parquet')}\")\n",
    "    else:\n",
    "        print(\"No se generaron nuevos eventos\")\n",
    "except Exception as e:\n",
    "    print(f\"Error en el procesamiento principal: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3040fc78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:07:09.042664Z",
     "iopub.status.busy": "2024-11-12T17:07:09.042505Z",
     "iopub.status.idle": "2024-11-12T17:07:09.045733Z",
     "shell.execute_reply": "2024-11-12T17:07:09.045489Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ver valores únicos de season_id\n",
    "unique_seasons = df_event_data['season_id'].unique()\n",
    "print(\"\\nTemporadas únicas en el dataset:\")\n",
    "print(unique_seasons)\n",
    "\n",
    "# Si quieres ver también cuántos eventos hay por temporada:\n",
    "season_counts = df_event_data['season_id'].value_counts()\n",
    "print(\"\\nNúmero de eventos por temporada:\")\n",
    "print(season_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3958203",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:07:09.061567Z",
     "iopub.status.busy": "2024-11-12T17:07:09.061410Z",
     "iopub.status.idle": "2024-11-12T17:07:09.119188Z",
     "shell.execute_reply": "2024-11-12T17:07:09.118918Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_event_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64244a36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:07:09.135646Z",
     "iopub.status.busy": "2024-11-12T17:07:09.135522Z",
     "iopub.status.idle": "2024-11-12T17:07:09.137418Z",
     "shell.execute_reply": "2024-11-12T17:07:09.137204Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_team_players = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc174f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:07:09.153870Z",
     "iopub.status.busy": "2024-11-12T17:07:09.153702Z",
     "iopub.status.idle": "2024-11-12T17:07:09.777229Z",
     "shell.execute_reply": "2024-11-12T17:07:09.776787Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_event_data.rename(columns={'id': \"event_id\"}, inplace=True)\n",
    "df_event_data = pd.merge(df_event_data, df_teams, left_on=\"team_id\", right_on=\"team_id\", how=\"left\", sort=False, suffixes=('', '_team'))\n",
    "df_event_data = pd.merge(df_event_data, df_matches, left_on=\"match_id\", right_on=\"match_id\", how=\"left\", sort=False, suffixes=('', '_match'))\n",
    "df_event_data = pd.merge(df_event_data, names_team_players, left_on=\"player_id\", right_on=\"player_id\", how=\"left\", sort=False, suffixes=('', '_player'))\n",
    "\n",
    "df_event_data['player_id'] = df_event_data['player_id'].fillna(0)\n",
    "df_event_data['team_id'] = df_event_data['team_id'].fillna(0)\n",
    "df_event_data['relative_event.id'] = df_event_data['relative_event.id'].fillna(0)\n",
    "\n",
    "df_event_data['player_id'] = df_event_data['player_id'].astype(int)\n",
    "df_event_data['team_id'] = df_event_data['team_id'].astype(int)\n",
    "df_event_data['relative_event.id'] = df_event_data['relative_event.id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa68379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:07:09.793968Z",
     "iopub.status.busy": "2024-11-12T17:07:09.793841Z",
     "iopub.status.idle": "2024-11-12T17:07:09.800172Z",
     "shell.execute_reply": "2024-11-12T17:07:09.799926Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_event_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a7be3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:07:09.817405Z",
     "iopub.status.busy": "2024-11-12T17:07:09.817274Z",
     "iopub.status.idle": "2024-11-12T17:07:09.819123Z",
     "shell.execute_reply": "2024-11-12T17:07:09.818908Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_event_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69983296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:07:09.835861Z",
     "iopub.status.busy": "2024-11-12T17:07:09.835704Z",
     "iopub.status.idle": "2024-11-12T17:07:58.503662Z",
     "shell.execute_reply": "2024-11-12T17:07:58.503320Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#POR CADA PARTIDO SOLICITADO ANTERIORMENTE HACEMOS UNA LLAMADA A LA API PIDIENDO LAS FORMACIONES\n",
    "all_formations = pd.DataFrame()\n",
    "\n",
    "def extract_formation_details(row):\n",
    "    formation = row['formation']\n",
    "    if isinstance(formation, str):\n",
    "        formation = ast.literal_eval(formation)\n",
    "    \n",
    "    new_rows = []\n",
    "    for player in formation:\n",
    "        new_row = row.copy()\n",
    "        new_row['player_id'] = player['player_id']\n",
    "        new_row['position_x'] = player['position']['x']\n",
    "        new_row['position_y'] = player['position']['y']\n",
    "        new_rows.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(new_rows)\n",
    "\n",
    "for indice_fila, fila in df_matches.iterrows():\n",
    "    if fila['season_id'] in season_resultantes:\n",
    "        total = 1000\n",
    "        offset = 0\n",
    "        \n",
    "        while total == 1000:\n",
    "            try:\n",
    "                formation = getResults(f\"/matches/{fila['match_id']}/formation\", {'limit': 5000, 'offset': offset})\n",
    "                \n",
    "                if 'result' in formation and formation['result']:\n",
    "                    ed = json_normalize(formation['result'])\n",
    "                    total = len(ed)\n",
    "                    ed['match_id'] = fila['match_id']\n",
    "                    ed['season_id'] = fila['season_id']\n",
    "                    \n",
    "                    # Extraer detalles de formación\n",
    "                    expanded_formations = ed.apply(extract_formation_details, axis=1)\n",
    "                    expanded_formations = pd.concat(expanded_formations.tolist(), ignore_index=True)\n",
    "                    \n",
    "                    all_formations = pd.concat([all_formations, expanded_formations], ignore_index=True)\n",
    "                    \n",
    "                    offset += 1000\n",
    "                else:\n",
    "                    print(f\"No se encontraron datos de formación para el partido {fila['match_id']}\")\n",
    "                    break\n",
    "            \n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if e.response.status_code == 404:\n",
    "                    print(f\"No se encontraron datos de formación para el partido {fila['match_id']}\")\n",
    "                else:\n",
    "                    print(f\"Error al obtener datos para el partido {fila['match_id']}: {e}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error inesperado al procesar el partido {fila['match_id']}: {e}\")\n",
    "                break\n",
    "\n",
    "# Eliminar las columnas 'formation' y 'position' si existen\n",
    "columns_to_drop = ['formation', 'position']\n",
    "all_formations = all_formations.drop(columns=[col for col in columns_to_drop if col in all_formations.columns])\n",
    "\n",
    "# Exportar todas las formaciones a un único parquet\n",
    "if not all_formations.empty:\n",
    "    output_path = os.path.join(BASE_PATH, f'formations_league_{league_id}.parquet')\n",
    "    all_formations.to_parquet(output_path, index=False)\n",
    "    print(f\"Se han guardado todas las formaciones en {output_path}\")\n",
    "    print(f\"Columnas en el archivo: {all_formations.columns.tolist()}\")\n",
    "    print(f\"Total de filas: {len(all_formations)}\")\n",
    "else:\n",
    "    print(\"No se encontraron formaciones para exportar.\")\n",
    "\n",
    "print(f\"Procesamiento completado. Se procesaron {len(all_formations)} filas de formaciones.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8b67c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:07:58.527244Z",
     "iopub.status.busy": "2024-11-12T17:07:58.527070Z",
     "iopub.status.idle": "2024-11-12T17:07:58.532195Z",
     "shell.execute_reply": "2024-11-12T17:07:58.531950Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_formations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca50aa02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:07:58.552338Z",
     "iopub.status.busy": "2024-11-12T17:07:58.552214Z",
     "iopub.status.idle": "2024-11-12T17:08:43.567798Z",
     "shell.execute_reply": "2024-11-12T17:08:43.566926Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#POR CADA PARTIDO SOLICITADO ANTERIORMENTE HACEMOS UNA LLAMADA A LA API PIDIENDO LAS ALINEACIONES\n",
    "\n",
    "# Asumiendo que ya tienes definido season_resultantes y df_matches\n",
    "all_lineups = pd.DataFrame()\n",
    "\n",
    "for indice_fila, fila in df_matches.iterrows():\n",
    "    if fila['season_id'] in season_resultantes:\n",
    "        total = 1000\n",
    "        offset = 0\n",
    "        \n",
    "        while total == 1000:\n",
    "            try:\n",
    "                lineup = getResults(f\"/matches/{fila['match_id']}/lineup\", {'limit': 5000, 'offset': offset})\n",
    "                \n",
    "                if 'result' in lineup and lineup['result']:\n",
    "                    ed = json_normalize(lineup['result'])\n",
    "                    total = len(ed)\n",
    "                    ed['match_id'] = fila['match_id']\n",
    "                    ed['season_id'] = fila['season_id']\n",
    "                    \n",
    "                    # Procesamos las columnas de posición\n",
    "                    if 'position.x' in ed.columns and 'position.y' in ed.columns:\n",
    "                        ed['position_x'] = ed['position.x']\n",
    "                        ed['position_y'] = ed['position.y']\n",
    "                    \n",
    "                    # Seleccionamos las columnas relevantes\n",
    "                    columnas = ['id', 'match_id', 'season_id', 'team_id', 'player_id', 'position_name', 'back_number', \n",
    "                                'player_name', 'player_last_name', 'is_starting_lineup', 'position_x', 'position_y']\n",
    "                    ed = ed[columnas]\n",
    "                    \n",
    "                    all_lineups = pd.concat([all_lineups, ed], ignore_index=True)\n",
    "                    offset += 1000\n",
    "                else:\n",
    "                    print(f\"No se encontraron alineaciones para el partido {fila['match_id']}\")\n",
    "                    break\n",
    "            \n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if e.response.status_code == 404:\n",
    "                    print(f\"No se encontraron alineaciones para el partido {fila['match_id']}\")\n",
    "                else:\n",
    "                    print(f\"Error al obtener alineaciones para el partido {fila['match_id']}: {e}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error inesperado al procesar el partido {fila['match_id']}: {e}\")\n",
    "                break\n",
    "\n",
    "# Exportar todas las alineaciones a un único parquet\n",
    "if not all_lineups.empty:\n",
    "    output_path = os.path.join(BASE_PATH, f'lineups_league_{league_id}.parquet')\n",
    "    all_lineups.to_parquet(output_path, index=False)\n",
    "    print(f\"Se han guardado todas las alineaciones en {output_path}\")\n",
    "    print(f\"Columnas en el archivo: {all_lineups.columns.tolist()}\")\n",
    "    print(f\"Total de filas: {len(all_lineups)}\")\n",
    "else:\n",
    "    print(\"No se encontraron alineaciones para exportar.\")\n",
    "\n",
    "print(f\"Procesamiento completado. Se procesaron {len(all_lineups)} filas de alineaciones.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c795c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:08:43.616135Z",
     "iopub.status.busy": "2024-11-12T17:08:43.615928Z",
     "iopub.status.idle": "2024-11-12T17:08:43.622196Z",
     "shell.execute_reply": "2024-11-12T17:08:43.621941Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_lineups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224c373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:08:43.649944Z",
     "iopub.status.busy": "2024-11-12T17:08:43.649786Z",
     "iopub.status.idle": "2024-11-12T17:09:55.785500Z",
     "shell.execute_reply": "2024-11-12T17:09:55.785102Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inicializamos el DataFrame para todas las secuencias\n",
    "all_sequences = pd.DataFrame()\n",
    "\n",
    "# Verificar si existe un archivo de secuencias previo\n",
    "output_path = os.path.join(BASE_PATH, f'sequence_data_league_{league_id}.parquet')\n",
    "existing_sequences = pd.DataFrame()\n",
    "if os.path.exists(output_path):\n",
    "    try:\n",
    "        existing_sequences = pd.read_parquet(output_path)\n",
    "        print(f\"Archivo existente encontrado con {len(existing_sequences)} secuencias\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer archivo existente: {str(e)}\")\n",
    "\n",
    "# Crear barra de progreso para todos los partidos nuevos\n",
    "total_matches = len(df_matches_new)\n",
    "print(f\"\\nProcesando secuencias para {total_matches} partidos nuevos\")\n",
    "\n",
    "for indice_fila, fila in tqdm(df_matches_new.iterrows(), total=total_matches, desc=\"Procesando partidos\"):\n",
    "    if fila['season_id'] in season_resultantes:\n",
    "        total = 1000\n",
    "        offset = 0\n",
    "        \n",
    "        while total == 1000:\n",
    "            try:\n",
    "                sequence_data = getResults(\n",
    "                    f\"/matches/{fila['match_id']}/sequence_data\", \n",
    "                    {'limit': 5000, 'offset': offset}\n",
    "                )\n",
    "                \n",
    "                if 'result' in sequence_data and sequence_data['result']:\n",
    "                    ed = json_normalize(sequence_data['result'])\n",
    "                    total = len(ed)\n",
    "                    \n",
    "                    if total > 0:\n",
    "                        # Añadir información del partido\n",
    "                        ed['match_id'] = fila['match_id']\n",
    "                        ed['season_id'] = fila['season_id']\n",
    "                        \n",
    "                        # Seleccionar las columnas necesarias\n",
    "                        columns_to_keep = [\n",
    "                            'team_id', 'match_id', 'season_id', \n",
    "                            'event_period', 'start_time', 'end_time', \n",
    "                            'event_ids'\n",
    "                        ]\n",
    "                        ed = ed[columns_to_keep]\n",
    "                        \n",
    "                        # Concatenar con las secuencias existentes\n",
    "                        all_sequences = pd.concat([all_sequences, ed], ignore_index=True)\n",
    "                        \n",
    "                        offset += 1000\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    print(f\"\\nNo se encontraron secuencias para el partido {fila['match_id']}\")\n",
    "                    break\n",
    "                \n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if e.response.status_code == 404:\n",
    "                    print(f\"\\nNo se encontraron secuencias para el partido {fila['match_id']}\")\n",
    "                else:\n",
    "                    print(f\"\\nError al obtener secuencias para el partido {fila['match_id']}: {e}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"\\nError inesperado al procesar el partido {fila['match_id']}: {e}\")\n",
    "                break\n",
    "\n",
    "# Exportar las nuevas secuencias\n",
    "if not all_sequences.empty:\n",
    "    # Si hay secuencias existentes, concatenarlas con las nuevas\n",
    "    if not existing_sequences.empty:\n",
    "        # Verificar y eliminar posibles duplicados basados en match_id y start_time\n",
    "        all_sequences = pd.concat([existing_sequences, all_sequences], ignore_index=True)\n",
    "        all_sequences = all_sequences.drop_duplicates(subset=['match_id', 'start_time'], keep='last')\n",
    "    \n",
    "    try:\n",
    "        # Guardar todas las secuencias\n",
    "        all_sequences.to_parquet(output_path, index=False)\n",
    "        print(f\"\\nSe han guardado todas las secuencias en {output_path}\")\n",
    "        print(f\"Columnas en el archivo: {all_sequences.columns.tolist()}\")\n",
    "        print(f\"Total de secuencias: {len(all_sequences)}\")\n",
    "        print(f\"Total de partidos únicos: {all_sequences['match_id'].nunique()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError al guardar el archivo: {str(e)}\")\n",
    "else:\n",
    "    print(\"\\nNo se encontraron nuevas secuencias para exportar.\")\n",
    "\n",
    "print(f\"\\nProcesamiento completado. Se procesaron {len(all_sequences)} secuencias en total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b3fa9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:09:55.829734Z",
     "iopub.status.busy": "2024-11-12T17:09:55.829472Z",
     "iopub.status.idle": "2024-11-12T17:09:55.833929Z",
     "shell.execute_reply": "2024-11-12T17:09:55.833698Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_sequences.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed948ba7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:09:55.866359Z",
     "iopub.status.busy": "2024-11-12T17:09:55.866212Z",
     "iopub.status.idle": "2024-11-12T17:10:49.592614Z",
     "shell.execute_reply": "2024-11-12T17:10:49.591877Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#POR CADA PARTIDO SOLICITADO ANTERIORMENTE HACEMOS UNA LLAMADA A LA API PIDIENDO LAS ESTADISTICAS POR EQUIPO\n",
    "# Asumiendo que ya tienes definido season_resultantes y df_matches\n",
    "all_team_stats = pd.DataFrame()\n",
    "\n",
    "for indice_fila, fila in df_matches.iterrows():\n",
    "    if fila['season_id'] in season_resultantes:\n",
    "        try:\n",
    "            team_stats = getResults(f\"/matches/{fila['match_id']}/team_stats\")\n",
    "            \n",
    "            if team_stats and 'result' in team_stats:\n",
    "                ed = json_normalize(team_stats['result'])\n",
    "                ed['match_id'] = fila['match_id']\n",
    "                ed['season_id'] = fila['season_id']\n",
    "                \n",
    "                # Expandir la columna 'stats' si existe\n",
    "                if 'stats' in ed.columns:\n",
    "                    stats_expanded = pd.json_normalize(ed['stats'])\n",
    "                    ed = pd.concat([ed.drop('stats', axis=1), stats_expanded], axis=1)\n",
    "                \n",
    "                all_team_stats = pd.concat([all_team_stats, ed], ignore_index=True)\n",
    "            else:\n",
    "                print(f\"No se encontraron team_stats para el partido {fila['match_id']}\")\n",
    "        \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 404:\n",
    "                print(f\"No se encontraron team_stats para el partido {fila['match_id']}\")\n",
    "            else:\n",
    "                print(f\"Error al obtener team_stats para el partido {fila['match_id']}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error inesperado al procesar el partido {fila['match_id']}: {e}\")\n",
    "\n",
    "# Exportar todos los team_stats a un único parquet\n",
    "if not all_team_stats.empty:\n",
    "    output_path = os.path.join(BASE_PATH, f'team_stats_league_{league_id}.parquet')\n",
    "    all_team_stats.to_parquet(output_path, index=False)\n",
    "    print(f\"Se han guardado todos los team_stats en {output_path}\")\n",
    "    print(f\"Columnas en el archivo: {all_team_stats.columns.tolist()}\")\n",
    "    print(f\"Total de filas: {len(all_team_stats)}\")\n",
    "else:\n",
    "    print(\"No se encontraron team_stats para exportar.\")\n",
    "\n",
    "print(f\"Procesamiento completado. Se procesaron {len(all_team_stats)} filas de team_stats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075cc6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:10:49.653514Z",
     "iopub.status.busy": "2024-11-12T17:10:49.653323Z",
     "iopub.status.idle": "2024-11-12T17:10:49.660935Z",
     "shell.execute_reply": "2024-11-12T17:10:49.660663Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_team_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4f10e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:10:49.696882Z",
     "iopub.status.busy": "2024-11-12T17:10:49.696740Z",
     "iopub.status.idle": "2024-11-12T17:12:01.588071Z",
     "shell.execute_reply": "2024-11-12T17:12:01.587543Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#POR CADA PARTIDO SOLICITADO ANTERIORMENTE HACEMOS UNA LLAMADA A LA API PIDIENDO LAS ESTADISTICAS POR JUGADOR\n",
    "\n",
    "# Asumiendo que ya tienes definido df_matches, season_resultantes, BASE_PATH y league_id\n",
    "all_player_stats = pd.DataFrame()\n",
    "\n",
    "for indice_fila, fila in df_matches.iterrows():\n",
    "    if fila['season_id'] in season_resultantes:\n",
    "        try:\n",
    "            player_stats = getResults(f\"/matches/{fila['match_id']}/player_stats\")\n",
    "            \n",
    "            if 'result' in player_stats and player_stats['result']:\n",
    "                for team_stats in player_stats['result']:\n",
    "                    team_id = team_stats['team_id']\n",
    "                    for player in team_stats['players']:\n",
    "                        player_data = player['stats']\n",
    "                        player_data['player_id'] = player['player_id']\n",
    "                        player_data['team_id'] = team_id\n",
    "                        player_data['match_id'] = fila['match_id']\n",
    "                        player_data['season_id'] = fila['season_id']\n",
    "                        \n",
    "                        df_player = pd.DataFrame([player_data])\n",
    "                        all_player_stats = pd.concat([all_player_stats, df_player], ignore_index=True)\n",
    "            else:\n",
    "                print(f\"No se encontraron estadísticas de jugadores para el partido {fila['match_id']}\")\n",
    "        \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 404:\n",
    "                print(f\"No se encontraron estadísticas de jugadores para el partido {fila['match_id']}\")\n",
    "            else:\n",
    "                print(f\"Error al obtener datos para el partido {fila['match_id']}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error inesperado al procesar el partido {fila['match_id']}: {e}\")\n",
    "\n",
    "# Exportar todas las estadísticas de jugadores a un único parquet\n",
    "if not all_player_stats.empty:\n",
    "    output_path = os.path.join(BASE_PATH, f'player_stats_extended_league_{league_id}.parquet')\n",
    "    all_player_stats.to_parquet(output_path, index=False)\n",
    "    print(f\"Se han guardado todas las estadísticas extendidas de jugadores en {output_path}\")\n",
    "    print(f\"Columnas en el archivo: {all_player_stats.columns.tolist()}\")\n",
    "    print(f\"Total de filas: {len(all_player_stats)}\")\n",
    "else:\n",
    "    print(\"No se encontraron estadísticas extendidas de jugadores para exportar.\")\n",
    "\n",
    "print(f\"Procesamiento completado. Se procesaron {len(all_player_stats)} filas de estadísticas extendidas de jugadores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a1da1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:12:01.636784Z",
     "iopub.status.busy": "2024-11-12T17:12:01.636616Z",
     "iopub.status.idle": "2024-11-12T17:12:01.642893Z",
     "shell.execute_reply": "2024-11-12T17:12:01.642659Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_player_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828de33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T17:12:01.680759Z",
     "iopub.status.busy": "2024-11-12T17:12:01.680627Z",
     "iopub.status.idle": "2024-11-12T17:12:01.684660Z",
     "shell.execute_reply": "2024-11-12T17:12:01.684396Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ver valores únicos y su frecuencia\n",
    "print(\"Frecuencia de cada season_id:\")\n",
    "print(df_matches['season_id'].value_counts())\n",
    "\n",
    "print(\"\\nValores únicos de season_id:\")\n",
    "print(df_matches['season_id'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.651216,
   "end_time": "2025-03-25T19:05:06.883425",
   "environment_variables": {},
   "exception": true,
   "input_path": "/Users/imac/Programas/Datos_API_Bepro/Alaves_Github/BePro/documentacion/notebooks/API Bepro_Alaves_Liga_Nacional_Juvenil_G4_parquet.ipynb",
   "output_path": "/Users/imac/Programas/Datos_API_Bepro/Alaves_Github/BePro/documentacion/notebooks/API Bepro_Alaves_Liga_Nacional_Juvenil_G4_parquet.ipynb",
   "parameters": {
    "alpha": 0.6,
    "ratio": 0.1
   },
   "start_time": "2025-03-25T19:05:00.232209",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}